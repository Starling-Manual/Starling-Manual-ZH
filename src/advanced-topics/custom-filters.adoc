== 自定义滤镜

你准备好开始行动了吗？
现在,我们正在进入自定义渲染代码的领域，让我们从一个简单的片段过滤器开始。

是的，这将涉及一些低级代码; 嘿嘿，你甚至需要写几行汇编程序！
但不要害怕，这不是火箭科学。
正如我的老数学老师曾经说过的：一个经过训练的猴子都能做到！

NOTE: 记住：滤镜是针对显示对象的每一个像素工作(换个说法:像素级)。
已过滤的对象将被渲染到纹理，然后通过自定义片段着色器（因此名称为fragment filter）进行处理。

=== 目标

我们选择一个尽量简单的目标，但它至少应该是一个有用的，对吧？
那就让我们创建一个ColorOffsetFilter(颜色偏移滤镜)吧。

你可能知道,可以通过给一个网格的任何顶点指定一种颜色来达到目的。
在渲染时，颜色将与纹理颜色相乘，这提供了一种非常简单（和快速）的方式来修改纹理的颜色。

[source, as3]
----
var image:Image = new Image(texture);
image.color = 0x808080; // R = G = B = 0.5
----

背后的数学非常简单：在GPU上，每个颜色通道（红色，绿色，蓝色）由0和1之间的值表示。
例如纯红色表示如下：

  R = 1, G = 0, B = 0

在渲染时，该颜色将乘以纹理的每个像素的颜色（也称为“纹素”）。
图像颜色的默认值为纯白色，意味着所有通道值都是1。
因此，纹理颜色看起来不变（与`1`的乘法结果是无操作）。
当你分配一个不同的颜色，经过乘法计算后将产生一种新的颜色，例如。

  R = 1,   G = 0.8, B = 0.6  ×
  B = 0.5, G = 0.5, B = 0.5
  -------------------------
  R = 0.5, G = 0.4, B = 0.3

这里有问题：这只会使对象变得更暗，而不是更亮。
这是因为我们只能乘以0和1之间的值;0意味着结果将是黑色的，而1意味着它保持不变。

.使用灰色显示图像。
image::customfilter-tinting.png[Tinting]

接下来我们想要解决滤镜的这个问题！
我们将在公式中包含offset。
(在经典Flash中，您可以使用 http://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/flash/geom/ColorTransform.html[ColorTransform].)

* 新红色值=（旧红色值×红色倍数）+ 红色偏移量
* 新绿色值=（旧绿色值×绿色倍数）+ 绿色偏移量
* 新蓝色值=（旧蓝色值×蓝色倍数）+ 蓝色偏移量
* 新透明值=（旧透明值×透明倍数）+ 透明偏移量

我们已经有了倍增器，因为它是在基本Mesh类中处理的;我们的滤镜只需要添加偏移量即可。

.向所有通道添加偏移量。
image::customfilter-offset.png[Offset]

现在进入正题,好吗?！ 

=== 扩展片段滤镜

所有的滤镜扩展自类'starling.filters.FragmentFilter`，这一个也不例外。
嘿，抓住了！我现在要扔给你一个完整的ColorOffsetFilter类;这不是代码片段，而是最终的完整代码！
我们不会再修改它。

[source, as3]
----
public class ColorOffsetFilter extends FragmentFilter
{
    public function ColorOffsetFilter(
        redOffset:Number=0, greenOffset:Number=0,
        blueOffset:Number=0, alphaOffset:Number=0):void
    {
        colorOffsetEffect.redOffset = redOffset;
        colorOffsetEffect.greenOffset = greenOffset;
        colorOffsetEffect.blueOffset = blueOffset;
        colorOffsetEffect.alphaOffset = alphaOffset;
    }

    override protected function createEffect():FilterEffect
    {
        return new ColorOffsetEffect();
    }

    private function get colorOffsetEffect():ColorOffsetEffect
    {
        return effect as ColorOffsetEffect;
    }

    public function get redOffset():Number
    {
        return colorOffsetEffect.redOffset;
    }

    public function set redOffset(value:Number):void
    {
        colorOffsetEffect.redOffset = value;
        setRequiresRedraw();
    }

    // the other offset properties need to be implemented accordingly.

    public function get/set greenOffset():Number;
    public function get/set blueOffset():Number;
    public function get/set alphaOffset():Number;
}
----

至目前为止，以上代码还是非常紧凑的，对吧？
但是我不得不承认：这个故事并没有讲完，因为我们也要写另一个类，来做实际的颜色处理工作。
无论如何，分析上面所看到的代码是非常值得的。

该类扩展自FragmentFilter，它覆盖了一个方法：`createEffect`。
以前你可能还没有遇到过`starling.rendering.Effect`类，因为只有低级渲染阶段才需要它。
通过阅读API文档可以得知：

====
Effect类封装了Stage3D绘图操作的所有步骤:
它配置渲染上下文，并设置着色器程序以及索引和顶点缓冲区，从而提供所有低级渲染的基本机制。
====

FragmentFilter类使用这个Effect类，或者Effect的子类FilterEffect。
对于这个简单的滤镜，我们只需要提供一个自定义的效果配置，我们通过重写“createEffect（）”方法来实现。
它只是通过属性来配置效果，并不做其它的工作。
在渲染时，基类将自动使用配置的效果来呈现滤镜。
仅此而已！

NOTE: 如果您想知道什么是“colorOffsetEffect”属性：它其实相当于一个快捷方式，能够访问配置的相关属性，而不会持续将其转换为ColorOffsetEffect。
基类也提供了一个`effect`属性，但它会返回一个类型为'FilterEffect`的对象 - 但我们需要完整的类型ColorOffsetEffect来访问“offset”属性。

更复杂的滤镜可能需要重写“process”方法;例如需要创建多通道滤镜。
但对于我们目前讨论的示例滤镜，不必重写此方法。

最后，请注意调用“setRequiresRedraw”：它确保在更改设置后重新呈现效果。
否则，Starling不会重绘对象。

=== 扩展FilterEffect

我们来做点实际的工作吧
FilterEffect子类是实现这个滤镜的重头戏。
这并不意味着它非常复杂，耐着性子听我讲完还是很容易理解的。

我们从一个尚未完成的代码开始：

[source, as3]
----
public class ColorOffsetEffect extends FilterEffect
{
    private var _offsets:Vector.<Number>;

    public function ColorOffsetEffect()
    {
        _offsets = new Vector.<Number>(4, true);
    }

    override protected function createProgram():Program
    {
        // TODO
    }

    override protected function beforeDraw(context:Context3D):void
    {
        // TODO
    }

    public function get redOffset():Number { return _offsets[0]; }
    public function set redOffset(value:Number):void { _offsets[0] = value; }

    public function get greenOffset():Number { return _offsets[1]; }
    public function set greenOffset(value:Number):void { _offsets[1] = value; }

    public function get blueOffset():Number { return _offsets[2]; }
    public function set blueOffset(value:Number):void { _offsets[2] = value; }

    public function get alphaOffset():Number { return _offsets[3]; }
    public function set alphaOffset(value:Number):void { _offsets[3] = value; }
}
----

Note that we're storing the offsets in a _Vector_, because that will make it easy to upload them to the GPU.
The `offset` properties read from and write to that vector.
Simple enough.

It gets more interesting when we look at the two overridden methods.

==== createProgram

This method is supposed to create the actual Stage3D shader code.

[NOTE]
====
I'll show you the basics, but explaining _Stage3D_ thoroughly is beyond the scope of this manual.
To get deeper into the topic, you can always have a look at one of the following tutorials:

  * http://www.adobe.com/devnet/flashplayer/articles/how-stage3d-works.html[How Stage3D works]
  * http://jacksondunstan.com/articles/1661[Introduction to AGAL]
  * http://help.adobe.com/en_US/as3/dev/WSd6a006f2eb1dc31e-310b95831324724ec56-8000.html[List of AGAL operations]
====

All Stage3D rendering is done through vertex- and fragment-shaders.
Those are little programs that are executed directly by the GPU, and they come in two flavors:

* *Vertex Shaders* are executed _once for each vertex_.
  Their input is made up from the vertex attributes we typically set up via the `VertexData` class; their output is the position of the vertex in screen coordinates.
* *Fragment Shaders* are executed _once for each pixel_ (fragment).
  Their input is made up of the _interpolated_ attributes of the three vertices of their triangle; the output is simply the color of the pixel.
* Together, a fragment and a vertex shader make up a *Program*.

The language filters are written in is called AGAL, an assembly language.
(Yes, you read right! This is as low-level as it gets.)
Thankfully, however, typical AGAL programs are very short, so it's not as bad as it sounds.

Good news: we only need to write a fragment shader.
The vertex shader is the same for most fragment filters, so Starling provides a standard implementation for that.
Let's look at the code:

[source, as3]
----
override protected function createProgram():Program
{
    var vertexShader:String = STD_VERTEX_SHADER;
    var fragmentShader:String =
        "tex ft0, v0, fs0 <2d, linear> \n" +
        "add oc, ft0, fc0";

    return Program.fromSource(vertexShader, fragmentShader);
}
----

As promised, the vertex shader is taken from a constant; the fragment shader is just two lines of code.
Both are combined into one _Program_ instance, which is the return value of the method.

The fragment shader requires some further elaboration, of course.

===== AGAL in a Nutshell

In AGAL, each line contains a simple method call.

  [opcode] [destination], [argument 1], ([argument 2])

* The first three letters are the name of the operation (`tex`, `add`).
* The next argument defines where the result of the operation is saved.
* The other arguments are the actual arguments of the method.
* All data is stored in predefined _registers_; think of them as _Vector3D_ instances (with properties for x, y, z and w).

There are several types of registers, e.g. for constants, temporary data or for the output of a shader.
In our shader, some of them already contain data; they were set up by other methods of the filter (we'll come to that later).

* `v0` contains the current texture coordinates (_varying register 0_)
* `fs0` points to the input texture (_fragment sampler 0_)
* `fc0` contains the color offset this is all about (_fragment constant 0_)

The result of a fragment shader must always be a color; that color is to be stored in the `oc` register.

===== Code Review

Let's get back to the actual code of our fragment shader.
The *first line* reads the color from the texture:

    tex ft0, v0, fs0 <2d, linear>

We're reading the texture `fs0` with the texture coordinates read from register `v0`, and some options (`2d, linear`).
The reason that the texture coordinates are in `v0` is just because the standard vertex shader (`STD_VERTEX_SHADER`) stores them there; just trust me on this one.
The result is stored in the temporary register `ft0` (remember: in AGAL, the result is always stored in the first argument of an operation).

[NOTE]
====
Now wait a minute. We never created any texture, right? What is this?

As I wrote above, a fragment filter works at the pixel level; its input is the original object, rendered into a texture.
Our base class (_FilterEffect_) sets that up for us; when the program runs, you can be sure that the texture sampler `fs0` will point to the pixels of the object being filtered.
====

You know what, actually I'd like to change this line a little.
You probably noticed the options at the end, indicating how the texture data should be interpreted.
Well, it turns out that these options depend on the texture type we're accessing.
To be sure the code works for every texture, let's use a helper method to write that AGAL operation.

[source, as3]
----
tex("ft0", "v0", 0, this.texture)
----

That does just the same (the method returns an AGAL string), but we don't need to care about the options any longer.
Always use this method when accessing a texture; it will let you sleep much better at night.

The *second line* is doing what we actually came here for: it adds the color offsets to the texel color.
The offset is stored in `fc0`, which we'll look at shortly; that's added to the `ft0` register (the texel color we just read) and stored in the output register (`oc`).

    add oc, ft0, fc0

That's it with AGAL for now.
Let's have a look at the other overridden method.

==== beforeDraw

The `beforeDraw` method is executed directly before the shaders are executed. We can use them to set up all the data required by our shader.

[source, as3]
----
override protected function beforeDraw(context:Context3D):void
{
    context.setProgramConstantsFromVector(Context3DProgramType.FRAGMENT, 0, _offsets);
    super.beforeDraw(context);
}
----

This is where we pass the offset values to the fragment shader.
The second parameter, `0`, defines the register that data is going to end up in.
If you look back at the actual shader code, you'll see that we read the offset from `fc0`, and that's exactly what we're filling up here: `fragment constant 0`.

The super call sets up all the rest, e.g. it assigns the texture (`fs0`) and the texture coordinates.

NOTE: Before you ask: yes, there is also an `afterDraw()` method, usually used to clean up one's resources.
But for constants, this is not necessary, so we can ignore it in this filter.

=== Trying it out

Our filter is ready, actually (download the complete code https://gist.github.com/PrimaryFeather/ba1e26d568320cd31086[here])!
Time to give it a test ride.

[source, as3]
----
var image:Image = new Image(texture);
var filter:ColorOffsetFilter = new ColorOffsetFilter();
filter.redOffset = 0.5;
image.filter = filter;
addChild(image);
----

.Our filter seems to have an ugly side effect.
image::customfilter-pma.png[Custom Filter PMA Issue]

Blimey!
Yes, the red value is definitely higher, but why is it now extending beyond the area of the bird!?
We didn't change the alpha value, after all!

Don't panic.
You just created your first filter, and it didn't blow up on you, right?
That must be worth something.
It's to be expected that there's some fine-tuning to do.

It turns out that we forgot to consider "premultiplied alpha" (PMA).
All conventional textures are stored with their RGB channels premultiplied with the alpha value.
So, a red with 50% alpha, like this:

  R = 1, G = 0, B = 0, A = 0.5

would actually be stored like this:

  R = 0.5, G = 0, B = 0, A = 0.5

And we didn't take that into account.
What he have to do is multiply the offset values with the alpha value of the current pixel before adding it to the output.
Here's one way to do that:

[source, as3]
----
tex("ft0", "v0", 0, texture)   // get color from texture
mov ft1, fc0                   // copy complete offset to ft1
mul ft1.xyz, fc0.xyz, ft0.www  // multiply offset.rgb with alpha (pma!)
add  oc, ft0, ft1              // add offset, copy to output
----

As you can see, we can access the `xyzw` properties of the registers to access individual color channels (they correspond with our `rgba` channels).

NOTE: What if the texture is not stored with PMA?
The `tex` method makes sure that we always receive the value with PMA, so no need to worry about that.

==== Second Try

When you give the filter another try now (complete code: https://gist.github.com/PrimaryFeather/31f1dd7f04cd6ce886f1[ColorOffsetFilter.as]), you'll see correct alpha values:

.That's more like it!
image::customfilter-pma-solved.png[Custom Filter with solved PMA issue]

Congratulations!
You just created your first filter, and it works flawlessly.
(Yes, you could have just used Starling's `ColorMatrixFilter` instead — but hey, this one is a tiny little bit faster, so it was well worth the effort.)

If you're feeling brave, you could now try to achieve the same with a mesh style instead.
It's not _that_ different, promised!
